{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, csv\n",
    "from urllib import request, error\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import boto3\n",
    "import random\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "import tempfile\n",
    "import pickle\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set constants\n",
    "model_dir = '../models'\n",
    "tfrecord_dir = 'tf_data_test'\n",
    "\n",
    "should_load_from_s3 = True\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "tfrecord_batch_size = 500\n",
    "num_classes = 14940\n",
    "\n",
    "height = 100\n",
    "width = 100\n",
    "color_mode = 'rgb'\n",
    "depth = 3 if color_mode == 'rgb' else 1\n",
    "\n",
    "n_layers_to_tune = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'landmark-data-12345'\n",
    "bucket = s3.Bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'data/sample_submission.csv'\n",
    "dest = '../data/sample_submission.csv'\n",
    "\n",
    "if not os.path.isfile(dest):\n",
    "    bucket.download_file(source, dest)\n",
    "\n",
    "sample_sub = pd.read_csv(dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 228 tfrecord files\n",
      "for example: s3://landmark-data-12345/tf_data_test/tfrecord_temp/1.tfrecord\n"
     ]
    }
   ],
   "source": [
    "if should_load_from_s3:\n",
    "    prefix = 's3://landmark-data-12345/'\n",
    "    filenames = [ prefix + obj.key for obj in bucket.objects.filter(Prefix=tfrecord_dir).all() if obj.key.endswith('tfrecord') ]\n",
    "else:\n",
    "    filenames = [ tfrecord_dir+filename for filename in os.listdir(tfrecord_dir) if filename.endswith('tfrecord') ]\n",
    "\n",
    "print('there are', len(filenames), 'tfrecord files')\n",
    "print('for example:', filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_batches = []\n",
    "id_batches = [] # correlate to batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 228 tfrecords\n",
      "2 of 228 tfrecords\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-45b3a1449fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m228\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mdecoded_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_byte_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mdecoded_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mpred_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# with jpeg string\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "pred_batch = []\n",
    "id_batch = []\n",
    "num_records = 0\n",
    "\n",
    "for idx, filename in enumerate(filenames):\n",
    "    print(idx+1, 'of', len(filenames), 'tfrecords')\n",
    "    record_iterator = tf.python_io.tf_record_iterator(path=filename)\n",
    "\n",
    "    for record_string in record_iterator:\n",
    "        num_records += 1\n",
    "        if len(pred_batch) == batch_size:\n",
    "            pred_batches.append(pred_batch)\n",
    "            pred_batch = []\n",
    "            id_batches.append(id_batch)\n",
    "            id_batch = []\n",
    "\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(record_string)\n",
    "\n",
    "        img_byte_string = example.features.feature['image'].bytes_list.value[0]\n",
    "        shape = example.features.feature['shape'].int64_list.value    \n",
    "        if len(shape) != 3:\n",
    "            print(shape)\n",
    "            continue\n",
    "\n",
    "        tempBuff = io.BytesIO()\n",
    "        tempBuff.write(img_byte_string)\n",
    "        tempBuff.seek(0)\n",
    "\n",
    "        image_data = Image.open(tempBuff).convert(\"RGB\")\n",
    "        image_data = np.array(image_data).reshape(shape)\n",
    "\n",
    "        id_int_list = example.features.feature['id'].int64_list.value\n",
    "\n",
    "        # add leading zeros to pad to num_char_per_hex\n",
    "        num_char_per_hex = 16//len(id_int_list)\n",
    "        id_string = ''.join([ \"{0:0{1}x}\".format(id_int, num_char_per_hex) for id_int in id_int_list ])\n",
    "\n",
    "        decoded_image = cv2.imdecode(np.frombuffer(img_byte_string, np.uint8), -1)\n",
    "        decoded_image = example.features.feature['image']\n",
    "        pred_batch.append(decoded_image)\n",
    "        id_batch.append(id_string)       \n",
    "\n",
    "if len(pred_batch) > 0:\n",
    "    pred_batches.append(pred_batch)\n",
    "    pred_batch = []\n",
    "    id_batches.append(id_batch)\n",
    "    id_batch = []\n",
    "    \n",
    "print('processed', num_records, 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131886\n"
     ]
    }
   ],
   "source": [
    "# resize the images \n",
    "print(len(pred_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fn(tensor):\n",
    "    features = {\n",
    "        'label': tf.FixedLenFeature([], dtype=tf.int64),\n",
    "        'image': tf.FixedLenFeature([], dtype=tf.string),\n",
    "#         'shape': tf.FixedLenFeature([], dtype=tf.int64)\n",
    "        'id': tf.FixedLenFeature([], dtype=tf.int64)\n",
    "    }\n",
    "    example = tf.parse_single_example(tensor, features)\n",
    "\n",
    "    image_data = tf.image.decode_jpeg(example['image'], channels=depth)\n",
    "    \n",
    "    x = tf.image.resize_image_with_pad(tf.cast(image_data, tf.float32), height, width)\n",
    "    \n",
    "    y = tf.one_hot(tf.cast(example['label'], tf.int32), num_classes)\n",
    "    \n",
    "    # todo: return id here?\n",
    "    return x, y\n",
    "\n",
    "dataset = TFRecordDataset(filenames)\n",
    "\n",
    "dataset = dataset.apply(tf.contrib.data.map_and_batch(\n",
    "    preprocess_fn, batch_size,\n",
    "    num_parallel_batches=n_workers))\n",
    "\n",
    "dataset = dataset.repeat()\n",
    "dataset = dataset.prefetch(tf.contrib.data.AUTOTUNE) # todo: test without prefetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "pre_model = applications.VGG19(weights=\"imagenet\", \n",
    "                           include_top=False, \n",
    "                           input_shape=(width, height, 3 if color_mode == 'rgb' else 1))\n",
    "\n",
    "model = Sequential()\n",
    "for idx, layer in enumerate(pre_model._layers):\n",
    "    if idx < len(pre_model._layers) - n_layers_to_tune:\n",
    "        layer.trainable = False\n",
    "    model.add(layer)\n",
    "    \n",
    "model.add(Flatten(input_shape=pre_model.output_shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              4719616   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1994)              2043850   \n",
      "=================================================================\n",
      "Total params: 27,837,450\n",
      "Trainable params: 7,813,066\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download weights\n",
    "num_batch_to_load = 4\n",
    "source = 'models/landmark_model_weights' + str(num_batch_to_load) + '.h5'\n",
    "dest = '../models/landmark_model_weights' + str(num_batch_to_load) + '.h5'\n",
    "\n",
    "if not os.path.isfile(dest):\n",
    "    bucket.download_file(source, dest)\n",
    "\n",
    "model.load_weights(dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(test_dataset.make_one_shot_iterator(),\n",
    "#             validation_data=validation_dataset.make_one_shot_iterator(),\n",
    "#             epochs=5, \n",
    "#             steps_per_epoch=steps_per_epoch,\n",
    "#             verbose=1,\n",
    "#             callbacks=[SaveEachEpoch()]\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing img 0 after 0.0002486705780029297 seconds\n",
      "processing img 121 after 50.73480296134949 seconds\n",
      "processing img 245 after 101.51376700401306 seconds\n",
      "processing img 373 after 148.15084385871887 seconds\n",
      "processing img 497 after 198.0821497440338 seconds\n",
      "processing img 624 after 247.4419093132019 seconds\n",
      "processing img 749 after 297.3329689502716 seconds\n",
      "processing img 873 after 346.7143979072571 seconds\n",
      "processing img 999 after 393.9162976741791 seconds\n",
      "processing img 1123 after 447.58734107017517 seconds\n",
      "processing img 1246 after 493.74377369880676 seconds\n",
      "processing img 1371 after 540.2479226589203 seconds\n",
      "processing img 1495 after 586.9122774600983 seconds\n",
      "processing img 1618 after 635.558272600174 seconds\n"
     ]
    }
   ],
   "source": [
    "# load training data\n",
    "preds = []\n",
    "idx = 0\n",
    "sub_idx = 0\n",
    "\n",
    "start = time.time()\n",
    "while idx < num_filekeys:\n",
    "    print('processing img',idx,'after',time.time()-start,'seconds')\n",
    "\n",
    "    pred_batch = []\n",
    "    batch_ids = []\n",
    "    while len(pred_batch) < batch_size*4:\n",
    "        if idx < num_filekeys:\n",
    "\n",
    "            filekey = filekeys[idx]\n",
    "            img_id = filekey.split('/')[2].split('.')[0] # get filename, minus jpg\n",
    "#             print('img id is',img_id)\n",
    "            curr_sub_id = sample_sub.iloc[sub_idx]['id']\n",
    "            while curr_sub_id != img_id:\n",
    "                print('but sub id is',curr_sub_id)\n",
    "                batch_ids.append(curr_sub_id)\n",
    "                pred_batch.append(np.zeros((height, width, depth)))\n",
    "                sub_idx += 1\n",
    "                curr_sub_id = sample_sub.iloc[sub_idx]['id']\n",
    "            \n",
    "            batch_ids.append(img_id)\n",
    "\n",
    "            img = load_s3_file(filekey)\n",
    "            processed_img = process_img(img)\n",
    "            pred_batch.append(processed_img)\n",
    "            idx += 1\n",
    "            sub_idx += 1\n",
    "\n",
    "    predictions = model.predict_on_batch(np.array(pred_batch))\n",
    "    \n",
    "    for i, prediction in enumerate(predictions):\n",
    "        pred_pruned_class = np.argmax(prediction)\n",
    "        pred_class = pruned_classes[pred_pruned_class]\n",
    "        confidence = np.max(prediction)\n",
    "        preds.append((batch_ids[i], pred_class, confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(preds), 'preds') # should be 117703"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df = pd.DataFrame()\n",
    "df['id'] = pd.Series([ pred[0] for pred in preds ])\n",
    "df['landmarks'] = pd.Series([ (str(pred[1]) + ' ' + str(pred[2])) for pred in preds ])\n",
    "df.to_csv('pickles/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
